sd (1,100)
mean(1:5)
sd (1:100)
demo (mean)
mean (1:4)
library(haven)
PKCR71FL <- read_sas("Downloads/PKCR71SD/PKCR71FL.SAS",
NULL)
library(haven)
PKCR71FL <- read_dta("Downloads/PK_2017-18_DHS_10162019_1642_140145/PKCR71DT/PKCR71FL.DTA")
View(PKCR71FL)
View(PKCR71FL)
library(haven)
PKIR71FL <- read_dta("Downloads/Machine Learning Project/Data/PK_2017-18_DHS_10162019_1642_140145/PKIR71DT/PKIR71FL.DTA")
View(PKIR71FL)
View(PKIR71FL)
View(PKIR71FL)
View(PKIR71FL)
View(PKIR71FL)
# Abby's Twitter API tokes
create_token(
app = "SURV727",
consumer_key = "5cRDeDWFYi05VntBoIqIPcE6s",
consumer_secret = "bn16jHvC9CaTyruxO1HsJvhdosO25vUyUn3RSZFrmzTHGpDywf",
access_token = "1181191211186606080-jPCRfVki97q38Eqw8tQclnq08Bjuad",
access_secret = "MAucp4yoOPX1PX9DFGPlTB0rBjQt5afaQhjJdc6rSEmWR")
#get the token
get_token()
library(rtweet)
create_token(
app = "SURV727",
consumer_key = "5cRDeDWFYi05VntBoIqIPcE6s",
consumer_secret = "bn16jHvC9CaTyruxO1HsJvhdosO25vUyUn3RSZFrmzTHGpDywf",
access_token = "1181191211186606080-jPCRfVki97q38Eqw8tQclnq08Bjuad",
access_secret = "MAucp4yoOPX1PX9DFGPlTB0rBjQt5afaQhjJdc6rSEmWR")
#get the token
get_token()
help(woeid)
??woeid
get_trends(coords = c(45.33, 116.55, 49, 124.46),
fromDate ="201810010000",toDate = "201811080000")
create_token(
app = "SURV727",
consumer_key = "5cRDeDWFYi05VntBoIqIPcE6s",
consumer_secret = "bn16jHvC9CaTyruxO1HsJvhdosO25vUyUn3RSZFrmzTHGpDywf",
access_token = "1181191211186606080-jPCRfVki97q38Eqw8tQclnq08Bjuad",
access_secret = "MAucp4yoOPX1PX9DFGPlTB0rBjQt5afaQhjJdc6rSEmWR")
#get the token
get_token()
get_trends(coords = c(45.33, 116.55, 49, 124.46),
fromDate ="201810010000",toDate = "201811080000")
get_trends(coords = c(45.33, 116.55, 49, 124.46))
get_trends_closest(coords = c(45.33, 116.55, 49, 124.46))
trends <- get_trends(coords = c(45.33, 116.55, 49, 124.46))
trends <- get_trends(coords = c(45.33, -116.55, 49, -124.46))
trends <- get_trends(bbox = c(-116.55, 45.33, -124.46, 49))
trends <- get_trends(bbox = c(-116.55, 45.33, -124.46, 49))
trends <- get_trends(long = -116.55, lat = 45.33)
yes_1631 <- search_fullarchive ("#Yesto1631",n = 100, env_name = "SURV727",
fromDate ="201810010000",toDate = "201811080000")
View(yes_1631)
View(yes_1631)
neutral <- search_fullarchive ("#1631",n = 100, env_name = "SURV727",
fromDate ="201810010000",toDate = "201811082359",
bbox = c(-116.55, 45.33, -124.46, 49))
neutral <- search_fullarchive ("#1631",n = 100, env_name = "SURV727",
fromDate ="201810010000",toDate = "201811082359")
View(neutral)
View(neutral)
neutral <- search_fullarchive ("Initiative1631", n = 100, env_name = "SURV727",
fromDate ="201810010000",toDate = "201811082359")
View(neutral)
View(neutral)
#getting yeson1631
yeson1631 <- search_fullarchive ("#YesOn1631",n = 100, env_name = "SURV727",
fromDate ="201810010000",toDate = "201811082359")
View(yeson1631)
#getting yeson1631, take 2 without a hashtag
yes_nohashtag <- search_fullarchive ("YesOn1631",n = 100, env_name = "SURV727",
fromDate ="201810010000",toDate = "201811082359")
View(yes_nohashtag)
View(yes_nohashtag)
quote_places <-
tweets %>%
select(status_id, quoted_location, text) %>%
group_by(quoted_location) %>%
tally()
library(rtweet)
library(dplyr)
quote_places <-
tweets %>%
select(status_id, quoted_location, text) %>%
group_by(quoted_location) %>%
tally()
quote_places <-
tweets %>%
select(status_id, quoted_location, text) %>%
group_by(quoted_location) %>%
tally()
quote_places <-
tweets %>%
select(status_id, quoted_location, text) %>%
group_by(quoted_location) %>%
tally()
quote_places <-
tweets %>%
select(status_id, quoted_location, text) %>%
group_by(quoted_location) %>%
tally()
#checking number of observations
NROW(tweets)
#uploading packages
library(rtweet)
library(dplyr)
#uploading new data
tweets <- read_csv("tweets.csv")
#checking number of observations
NROW(tweets)
#checking place names
places <-
tweets %>%
select(status_id, place_name, text) %>%
group_by(place_name)%>%
tally()
#checking quotes locations
quote_places <-
tweets %>%
select(status_id, quoted_location, text) %>%
group_by(quoted_location) %>%
tally()
tweets <- read_csv("tweets.csv")
library(rtweet)
library(dplyr)
tweets <- read_csv("tweets.csv")
NROW(tweets)
library(tidyr)
tweets <- read_csv("tweets.csv")
#checking number of observations
NROW(tweets)
#checking place names
places <-
tweets %>%
select(status_id, place_name, text) %>%
group_by(place_name)%>%
tally()
#checking quotes locations
quote_places <-
tweets %>%
select(status_id, quoted_location, text) %>%
group_by(quoted_location) %>%
tally()
tweets <- read_csv("tweets.csv")
tweets <- read.csv("tweets.csv")
tweets <- read_csv("tweets.csv")
library(tidyr)
tweets <- read_csv("tweets.csv")
library(readr)
tweets <- read_csv("tweets.csv")
library(readr)
tweets <- read_csv("~/Data-cleaning/class-10/tweets.csv")
View(tweets)
quote_places <-
tweets %>%
select(status_id, quoted_location, text) %>%
group_by(quoted_location) %>%
tally()
quote_places
View(quote_places)
places <-
tweets %>%
select(status_id, place_name, text) %>%
group_by(place_name)%>%
tally()
places
View(places)
View(places)
users_data(tweets)
users <- users_data(tweets)
View(users)
View(users)
save_as_csv(users, users.csv)
save_as_csv(users)
save_as_csv(users, file_name = "twitter-users")
users %>%
select(screen_name, location, follwers_count) %>%
group_by(location)
users %>%
select(screen_name, location, followers_count) %>%
group_by(location)
users-location <-
users %>%
select(screen_name, location, followers_count) %>%
group_by(location)
users-location <-
users %>%
select(screen_name, location, followers_count) %>%
group_by(location)
users-location <-
users %>%
select(screen_name, location, followers_count) %>%
group_by(location)
users_location <-
users %>%
select(screen_name, location, followers_count) %>%
group_by(location)
View(users_location)
View(users_location)
users_location <-
users %>%
select(screen_name, location, followers_count) %>%
group_by(location) %>%
tally()
View(users_location)
View(users_location)
library(rtweet)
library(dplyr)
library(tidyr)
library(readr)
library(rjson)
#setting working directory
setwd("~/Data-cleaning/final-paper/data")
#uploading tweet data
tweets <- read_csv("tweets.csv")
#uploading user data pulled from the tweet data
users <- read_csv("twitter-users.csv")
#importing voting reuslts
votes <- read_csv("~/Data-cleaning/final-paper/data/washington-2018-results.csv")
head(votes)
#uploading list of cities in washington to match with user information
cities <- read_csv("washington-cities.csv")
#we drop the NAs
users2 <-
users %>%
select(user_id, location, screen_name) %>%
drop_na(.)
#seperate the location column into city and state
users2 <- separate(users2, location, into = c("city","state"), sep= (","))
#get rid of all the white space
users2 <-
users2 %>%
select(user_id, screen_name, city) %>%
mutate(city = tolower(trimws(.$city)))
#then we need to clean the cities data
cities <-
cities %>%
mutate(city = tolower(trimws(.$city, "l")))
View(cities)
View(cities)
colnames(cities)[1] <- "city"
colnames(cities)[2] <- "county"
cities <-
cities %>%
mutate(city = tolower(trimws(.$city, "l")))
cities$city <- (gsub("\\s", "", cities$city))
full_location <- merge(users3, cities, by = "city")
full_location <- merge(users2, cities, by = "city")
View(full_location)
View(full_location)
full_location <-
full_location %>%
select(user_id, screen_name, city, county)
#annoyingly full_location has an extra x in the user id so need to remove
full_location$user_id <- gsub("x", "", full_location$user_id)
tweets$user_id <- gsub("x", "", tweets$user_id)
#merge user location with actual tweets
tweets_location <-
full_location %>% semi_join(tweets, by = "user_id")
View(full_location)
View(full_location)
View(tweets_location)
View(tweets_location)
votes <-
votes %>%
select(County, Race, Candidate, Votes, PercentageOfTotalVotes) %>%
filter(Race == "State Measures Initiative Measure No. 1639 Initiative Measure No. 1639 concerns firearms.")
View(tweets_location)
View(tweets_location)
View(tweets)
View(tweets)
colnames(tweets)
tweets_location <-
tweets %>%
select(user_id, screen_name, text, is_retweet, favorite_count, reply_count, retweet_count, hashtags, follwers_count)  %>%
tweets %>% semi_join(full_location, by = "user_id")
#merge user location with actual tweets
tweets_location <-
tweets %>%
select(user_id, screen_name, text, is_retweet, favorite_count, reply_count, retweet_count, hashtags, followers_count)  %>%
tweets %>% semi_join(full_location, by = "user_id")
tweets_location <-
tweets %>%
select(user_id, screen_name, text, is_retweet, favorite_count,
reply_count, retweet_count, hashtags, followers_count)  %>%
semi_join(full_location, by = "user_id")
View(full_location)
View(full_location)
View(tweets)
View(tweets)
View(tweets_location)
View(tweets_location)
View(votes)
View(votes)
View(tweets_location)
View(tweets_location)
tweets_location <-
tweets %>%
select(user_id, screen_name, text, is_retweet, favorite_count,
reply_count, retweet_count, hashtags, followers_count) %>%
merge(full_location, tweets by = "user_id")
tweets_location <-
tweets %>%
select(user_id, screen_name, text, is_retweet, favorite_count,
reply_count, retweet_count, hashtags, followers_count) %>%
merge(full_location, tweets, by = "user_id")
View(tweets)
View(tweets)
View(full_location)
View(full_location)
tweets_location <-
tweets %>%
select(user_id, screen_name, text, is_retweet, favorite_count,
reply_count, retweet_count, hashtags, followers_count) %>%
semi_join(full_location, tweets, by = "user_id")
View(tweets_location)
View(tweets_location)
tweets_location <-
tweets %>%
select(user_id, screen_name, text, is_retweet, favorite_count,
reply_count, retweet_count, hashtags, followers_count) %>%
semi_join(full_location, by = "user_id")
tweets_location <- merge(tweets_location, full_location, by = "user_id")
View(tweets_location)
View(tweets_location)
tweets_location <- semi_join(tweets_location, full_location, by = "user_id")
View(tweets_location)
View(tweets_location)
tweets_location <-
tweets %>%
select(user_id, screen_name, text, is_retweet, favorite_count,
reply_count, retweet_count, hashtags, followers_count)
online_users <- semi_join(tweets_location, full_location, by = "user_id")
View(online_users)
View(online_users)
online_users <- merge(tweets_location, full_location, by = "user_id")
View(online_users)
View(online_users)
library(ggmap)
citation("ggmap")
View(votes)
View(votes)
state = c(left = -124.84, bottom = 45.54,right = -116.92, top = 49.0)
get_stamenmap(state, zoom = 10, maptype = "toner-lite") %>% ggmap()
map <- get_stamenmap(state, zoom = 10, maptype = "toner-lite") %>% ggmap()
map <- get_stamenmap(state, zoom = 1, maptype = "toner-lite") %>% ggmap()
map
map <- get_stamenmap(state, zoom = 3, maptype = "toner-lite") %>% ggmap()
map
map <- get_stamenmap(state, zoom = 5, maptype = "toner-lite") %>% ggmap()
map
map <- get_stamenmap(state, zoom = 6, maptype = "toner-lite") %>% ggmap()
map
map <- get_stamenmap(state, zoom = 7, maptype = "toner-lite") %>% ggmap()
map
ggmap(map) +
geom_point(data= votes, aes(x = county, y = votes), size = 1)
ggmap() +
geom_point(data= votes, aes(x = county, y = votes), size = 1)
ggmap(map) +
geom_point(data= votes, aes(x = county, y = votes), size = 1)
qmap(map) +
geom_point(data= votes, aes(x = county, y = votes), size = 1)
qmplot(map) +
geom_point(data= votes, aes(x = county, y = votes), size = 1)
qmplot(state, data = votes, maptype = "toner-lite")
votes %>%
filter(Candidate == "Yes") %>%
qmplot(state, data = map)
votes %>%
filter(Candidate == "Yes") %>%
qmplot(state)
