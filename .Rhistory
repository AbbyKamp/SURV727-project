consumer_key = "5cRDeDWFYi05VntBoIqIPcE6s",
consumer_secret = "bn16jHvC9CaTyruxO1HsJvhdosO25vUyUn3RSZFrmzTHGpDywf",
access_token = "1181191211186606080-jPCRfVki97q38Eqw8tQclnq08Bjuad",
access_secret = "MAucp4yoOPX1PX9DFGPlTB0rBjQt5afaQhjJdc6rSEmWR")
#get the token
get_token()
library(rtweet)
create_token(
app = "SURV727",
consumer_key = "5cRDeDWFYi05VntBoIqIPcE6s",
consumer_secret = "bn16jHvC9CaTyruxO1HsJvhdosO25vUyUn3RSZFrmzTHGpDywf",
access_token = "1181191211186606080-jPCRfVki97q38Eqw8tQclnq08Bjuad",
access_secret = "MAucp4yoOPX1PX9DFGPlTB0rBjQt5afaQhjJdc6rSEmWR")
#get the token
get_token()
help(woeid)
??woeid
get_trends(coords = c(45.33, 116.55, 49, 124.46),
fromDate ="201810010000",toDate = "201811080000")
create_token(
app = "SURV727",
consumer_key = "5cRDeDWFYi05VntBoIqIPcE6s",
consumer_secret = "bn16jHvC9CaTyruxO1HsJvhdosO25vUyUn3RSZFrmzTHGpDywf",
access_token = "1181191211186606080-jPCRfVki97q38Eqw8tQclnq08Bjuad",
access_secret = "MAucp4yoOPX1PX9DFGPlTB0rBjQt5afaQhjJdc6rSEmWR")
#get the token
get_token()
get_trends(coords = c(45.33, 116.55, 49, 124.46),
fromDate ="201810010000",toDate = "201811080000")
get_trends(coords = c(45.33, 116.55, 49, 124.46))
get_trends_closest(coords = c(45.33, 116.55, 49, 124.46))
trends <- get_trends(coords = c(45.33, 116.55, 49, 124.46))
trends <- get_trends(coords = c(45.33, -116.55, 49, -124.46))
trends <- get_trends(bbox = c(-116.55, 45.33, -124.46, 49))
trends <- get_trends(bbox = c(-116.55, 45.33, -124.46, 49))
trends <- get_trends(long = -116.55, lat = 45.33)
yes_1631 <- search_fullarchive ("#Yesto1631",n = 100, env_name = "SURV727",
fromDate ="201810010000",toDate = "201811080000")
View(yes_1631)
View(yes_1631)
neutral <- search_fullarchive ("#1631",n = 100, env_name = "SURV727",
fromDate ="201810010000",toDate = "201811082359",
bbox = c(-116.55, 45.33, -124.46, 49))
neutral <- search_fullarchive ("#1631",n = 100, env_name = "SURV727",
fromDate ="201810010000",toDate = "201811082359")
View(neutral)
View(neutral)
neutral <- search_fullarchive ("Initiative1631", n = 100, env_name = "SURV727",
fromDate ="201810010000",toDate = "201811082359")
View(neutral)
View(neutral)
#getting yeson1631
yeson1631 <- search_fullarchive ("#YesOn1631",n = 100, env_name = "SURV727",
fromDate ="201810010000",toDate = "201811082359")
View(yeson1631)
#getting yeson1631, take 2 without a hashtag
yes_nohashtag <- search_fullarchive ("YesOn1631",n = 100, env_name = "SURV727",
fromDate ="201810010000",toDate = "201811082359")
View(yes_nohashtag)
View(yes_nohashtag)
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
library(rtweet)
library(tidyverse)
library(dplyr)
library(tidyverse)
library(gtrendsR)
library(censusapi)
library(reshape2)
load("/Users/user/Desktop/Twitter/Twitter R data.RData")
load("/Users/user/Desktop/Twitter/Location data.RData")
library(rtweet)
library(tidyverse)
library(dplyr)
library(tidyverse)
library(gtrendsR)
library(censusapi)
library(reshape2)
load("/Users/user/Desktop/Twitter/Twitter R data.RData")
load("/Users/user/Desktop/Twitter/Location data.RData")
#identifying bad strings
bad_strings <-  twitter_users_excel$location
twitter_users_excel$ss <- strsplit(bad_strings, ", ", fixed= TRUE)
colsplit(twitter_users_excel$ss, ", ", c("A", "B"))
loc <- data.frame(colsplit(twitter_users_excel$ss, ", ", c("A", "B")))
#webscrapping class
as.numericgsub(pattern)
#identifying bad strings
bad_strings <-  twitter_users_excel$location
twitter_users_excel$ss <- strsplit(bad_strings, ", ", fixed= TRUE)
colsplit(twitter_users_excel$ss, ", ", c("A", "B"))
loc <- data.frame(colsplit(twitter_users_excel$ss, ", ", c("A", "B")))
#webscrapping class
twitter_users_excel$a <- as.character(gsub("c(","", twitter_users_excel$a))
#identifying bad strings
bad_strings <-  twitter_users_excel$location
twitter_users_excel$ss <- strsplit(bad_strings, ", ", fixed= TRUE)
colsplit(twitter_users_excel$ss, ", ", c("A", "B"))
loc <- data.frame(colsplit(twitter_users_excel$ss, ", ", c("A", "B")))
#webscrapping class
twitter_users_excel$a <- as.character(gsub("[c(]","", twitter_users_excel$a))
#identifying bad strings
bad_strings <-  twitter_users_excel$location
twitter_users_excel$ss <- strsplit(bad_strings, ", ", fixed= TRUE)
colsplit(twitter_users_excel$ss, ", ", c("A", "B"))
loc <- data.frame(colsplit(twitter_users_excel$ss, ", ", c("A", "B")))
#webscrapping class
twitter_users_excel$a <- as.character(gsub("[c("]","", twitter_users_excel$a))
#identifying bad strings
bad_strings <-  twitter_users_excel$location
twitter_users_excel$ss <- strsplit(bad_strings, ", ", fixed= TRUE)
colsplit(twitter_users_excel$ss, ", ", c("A", "B"))
loc <- data.frame(colsplit(twitter_users_excel$ss, ", ", c("A", "B")))
#webscrapping class
twitter_users_excel$a <- as.character(gsub("c("","", twitter_users_excel$a))
#identifying bad strings
bad_strings <-  twitter_users_excel$location
twitter_users_excel$ss <- strsplit(bad_strings, ", ", fixed= TRUE)
colsplit(twitter_users_excel$ss, ", ", c("A", "B"))
loc <- data.frame(colsplit(twitter_users_excel$ss, ", ", c("A", "B")))
#webscrapping class
twitter_users_excel$a <- as.character(gsub("c("","", twitter_users_excel$a))
View(twitter_users_excel)
#identifying bad strings
bad_strings <-  twitter_users_excel$location
twitter_users_excel$ss <- strsplit(bad_strings, ", ", fixed= TRUE)
colsplit(twitter_users_excel$ss, ", ", c("A", "B"))
loc <- data.frame(colsplit(twitter_users_excel$ss, ", ", c("A", "B")))
#webscrapping class
#stats_dat$niche_grade <- gsub("Overall Niche Grade", "", stats_dat$niche_grade)
#stats_dat$acceptance_rate <- as.numeric(gsub("[^0123456789,]", "", stats_dat$acceptance_rate))
View(twitter_users_excel)
#identifying bad strings
bad_strings <-  twitter_users_excel$location
twitter_users_excel$ss <- strsplit(bad_strings, ", ", fixed= TRUE)
colsplit(twitter_users_excel$ss, ", ", c("A", "B"))
loc <- data.frame(colsplit(twitter_users_excel$ss, ", ", c("A", "B")))
View(loc)
View(loc)
loc$A  <- as.character(gsub("c(", "", loc$A))
loc$A  <- as.character(gsub("c(", "",loc$A))
library(caret)
library(randomForest)
library(partykit)
library(pROC)
drugs <- read.csv("drug_consumption.data", header = FALSE)
names(drugs) <- c("ID", "Age", "Gender", "Education", "Country", "Ethnicity", "Neuroticism", "Extraversion", "Openness", "Agreeableness", "Conscientiousness", "Impulsive", "SS", "Alcohol", "Amphet", "Amyl", "Benzos", "Caff", "Cannabis", "Choc", "Coke", "Crack", "Ecstasy", "Heroin", "Ketamine", "Legalh", "LSD", "Meth", "Mushrooms", "Nicotine", "Semer", "VSA")
drugs$Age <- as.factor(drugs$Age)
drugs$Gender  <- as.factor(drugs$Gender)
drugs$Education  <- as.factor(drugs$Education)
drugs$Country <- as.factor(drugs$Country)
drugs$Ethnicity <- as.factor(drugs$Ethnicity)
head(drugs)
# build a binary outcome variable
drugs$D_Meth <- "Meth"
drugs$D_Meth[drugs$Meth == "CL0"] <- "no_Meth"
drugs$D_Meth <- as.factor(drugs$D_Meth)
drugs$D_Meth <- relevel(drugs$D_Meth, "no_Meth")
table(drugs$Meth, drugs$D_Meth)
summary(drugs$D_Meth)
set.seed(9574)
inTrain <- createDataPartition(drugs$D_Meth,
p = .8,
list = FALSE,
times = 1)
drugs_train <- drugs[inTrain,]
drugs_test <- drugs[-inTrain,]
ctrl  <- trainControl(method = "cv",
number = 10,
summaryFunction = twoClassSummary,
classProbs = TRUE)
grid <- expand.grid(mtry = c(sqrt(ncol(drugs_train )),
log(ncol(drugs_train))),
splitrule = c("gini", "extratrees"),
min.node.size = 10)
grid
set.seed(9282)
rf <- train(D_Meth ~ Age + Gender + Education + Neuroticism + Extraversion +
Openness + Agreeableness + Conscientiousness + Impulsive + SS,
data = drugs_train,
method = "ranger",
trControl = ctrl,
tuneGrid = grid,
metric = "ROC",
importance = "impurity")
rf
# variable importance
plot(varImp(rf), top = 10)
# neuroticism and openness are the two most important variable.
# Partial plots
pdp1 <- partial(rf,pred.var = "Neuroticism",
type = "classification",
which.class = 1, prob = T)
# variable importance
plot(varImp(rf), top = 10)
# neuroticism and openness are the two most important variable.
# Partial plots
pdp1 <- partial(rf,pred.var = "Neuroticism",
type = "classification",
which.class = 1, prob = T)
# variable importance
plot(varImp(rf), top = 10)
# neuroticism and openness are the two most important variable.
# Partial plots
pdp1 <- partial(rf,pred.var = "Neuroticism",
type = "classification",
which.class = 1, prob = T)
# variable importance
plot(varImp(rf), top = 10)
# neuroticism and openness are the two most important variable.
# Partial plots
pdp1 <- partial(rf,pred.var = "Neuroticism",
type = "classification",
which.class = 1, prob = T)
# variable importance
plot(varImp(rf), top = 10)
# neuroticism and openness are the two most important variable.
# Partial plots
pdp1 <- partial(rf,pred.var = "Neuroticism",
type = "classification",
which.class = 1, prob = T)
library(caret)
library(randomForest)
library(partykit)
library(pROC)
drugs <- read.csv("drug_consumption.data", header = FALSE)
names(drugs) <- c("ID", "Age", "Gender", "Education", "Country", "Ethnicity", "Neuroticism", "Extraversion", "Openness", "Agreeableness", "Conscientiousness", "Impulsive", "SS", "Alcohol", "Amphet", "Amyl", "Benzos", "Caff", "Cannabis", "Choc", "Coke", "Crack", "Ecstasy", "Heroin", "Ketamine", "Legalh", "LSD", "Meth", "Mushrooms", "Nicotine", "Semer", "VSA")
drugs$Age <- as.factor(drugs$Age)
drugs$Gender  <- as.factor(drugs$Gender)
drugs$Education  <- as.factor(drugs$Education)
drugs$Country <- as.factor(drugs$Country)
drugs$Ethnicity <- as.factor(drugs$Ethnicity)
head(drugs)
# build a binary outcome variable
drugs$D_Meth <- "Meth"
drugs$D_Meth[drugs$Meth == "CL0"] <- "no_Meth"
drugs$D_Meth <- as.factor(drugs$D_Meth)
drugs$D_Meth <- relevel(drugs$D_Meth, "no_Meth")
table(drugs$Meth, drugs$D_Meth)
summary(drugs$D_Meth)
set.seed(9574)
inTrain <- createDataPartition(drugs$D_Meth,
p = .8,
list = FALSE,
times = 1)
drugs_train <- drugs[inTrain,]
drugs_test <- drugs[-inTrain,]
ctrl  <- trainControl(method = "cv",
number = 10,
summaryFunction = twoClassSummary,
classProbs = TRUE)
grid <- expand.grid(mtry = c(sqrt(ncol(drugs_train )),
log(ncol(drugs_train))),
splitrule = c("gini", "extratrees"),
min.node.size = 10)
grid
set.seed(9282)
rf <- train(D_Meth ~ Age + Gender + Education + Neuroticism + Extraversion +
Openness + Agreeableness + Conscientiousness + Impulsive + SS,
data = drugs_train,
method = "ranger",
trControl = ctrl,
tuneGrid = grid,
metric = "ROC",
importance = "impurity")
rf
# variable importance
plot(varImp(rf), top = 10)
# neuroticism and openness are the two most important variable.
# Partial plots
pdp1 <- partial(rf,pred.var = "Neuroticism",
type = "classification",
which.class = 1, prob = T)
# variable importance
plot(varImp(rf), top = 10)
# neuroticism and openness are the two most important variable.
# Partial plots
pdp1 <- partial(rf,pred.var = "Neuroticism",
type = "classification",
which.class = 1, prob = T)
# variable importance
plot(varImp(rf), top = 10)
# neuroticism and openness are the two most important variable.
# Partial plots
pdp1 <- partial(rf,pred.var = "Neuroticism",
type = "classification",
which.class = 1, prob = T)
# variable importance
plot(varImp(rf), top = 10)
# neuroticism and openness are the two most important variable.
# Partial plots
pdp1 <- partial(rf,pred.var = "Neuroticism",
type = "classification",
which.class = 1, prob = T)
# variable importance
plot(varImp(rf), top = 10)
# neuroticism and openness are the two most important variable.
# Partial plots
pdp1 <- partial(rf,pred.var = "Neuroticism",
type = "classification",
which.class = 1, prob = T)
# variable importance
plot(varImp(rf), top = 10)
# neuroticism and openness are the two most important variable.
# Partial plots
pdp1 <- partial(rf,pred.var = "Neuroticism",
type = "classification",
which.class = 1, prob = T)
# variable importance
plot(varImp(rf), top = 10)
# neuroticism and openness are the two most important variable.
# Partial plots
pdp1 <- partial(rf,pred.var = "Neuroticism",
type = "classification",
which.class = 1, prob = T)
# variable importance
plot(varImp(rf), top = 10)
# neuroticism and openness are the two most important variable.
# Partial plots
pdp1 <- partial(rf,pred.var = "Neuroticism",
type = "classification",
which.class = 1, prob = T)
# variable importance
plot(varImp(rf), top = 10)
# neuroticism and openness are the two most important variable.
# Partial plots
pdp1 <- partial(rf,pred.var = "Neuroticism",
type = "classification",
which.class = 1, prob = T)
# variable importance
plot(varImp(rf), top = 10)
# neuroticism and openness are the two most important variable.
# Partial plots
pdp1 <- partial(rf,pred.var = "Neuroticism",
type = "classification",
which.class = 1, prob = T)
grid2 <- expand.grid(mincriterion = c(0.05,0.5,0.95, 0.999))
grid2
rf2 <- train(D_Meth ~ Age + Gender + Education + Neuroticism + Extraversion +
Openness + Agreeableness + Conscientiousness + Impulsive + SS,
data = drugs_train,
method = "ctree",
tuneGrid = grid2)
rf2
# Random forest
y_rf <- predict(rf, newdata = drugs_test)
p_rf2<- predict(rf, newdata = drugs_test, type = "prob")
# class probabilities (RF)
confusionMatrix(y_rf, drugs_test$D_Meth)
# ctree
y_ctree <- predict(rf2,newdata = drugs_test)
p_ctree2<- predict(rf2, newdata = drugs_test, type = "prob")
# class probabilities (ctree)
confusionMatrix(y_ctree, drugs_test$D_Meth)
#It is often useful to first get an idea of prediction performance independent of specific classification thresholds. Use the `pROC` (or `PRROC`) package to create roc objects for both risk score vectors.
roc1 <- roc(drugs_test$D_Meth, p_rf2$Meth)
roc2 <- roc(drugs_test$D_Meth, p_ctree2$Meth)
#Random Forest
roc1
plot(roc1, scale.color = heat.colors(100))
roc1
#ctree
roc2
plot(roc2, scale.color = heat.colors(100))
roc2
#The ROC curve is created by evaluating the class probabilities for the model across a continuum of thresholds. For each candidate threshold, the resulting true-positive rate (i.e., the sensitivity) and the false-positive rate (one minus the specificity) are plotted against each other.The ROC curve can also be used for a quantitative assessment of the model. A perfect model that completely separates the two classes would have 100% sensitivity and specificity.The optimal model should also be shifted towards the upper left corner of the plot. Alternatively, the model with the largest area under the ROC curve. In this case, the first model has a better prediction performance. area under the curve rf 0.7628 > ctree 0.6754
# variable importance
plot(varImp(rf), top = 10)
# neuroticism and openness are the two most important variable.
# Partial plots
pdp1 <- partial(rf,pred.var = "Neuroticism",
type = "classification",
which.class = 1, prob = T)
# variable importance
plot(varImp(rf), top = 10)
# neuroticism and openness are the two most important variable.
# Partial plots
pdp1 <- partial(rf,pred.var = "Neuroticism",
type = "classification",
which.class = 1, prob = T)
# variable importance
plot(varImp(rf), top = 10)
# neuroticism and openness are the two most important variable.
# Partial plots
pdp1 <- partial(rf,pred.var = "Neuroticism",
type = "classification",
which.class = 1, prob = T)
# variable importance
plot(varImp(rf), top = 10)
# neuroticism and openness are the two most important variable.
# Partial plots
pdp1 <- partial(rf,pred.var = "Neuroticism",
type = "classification",
which.class = 1, prob = T)
library(caret)
library(randomForest)
library(partykit)
library(pROC)
drugs <- read.csv("drug_consumption.data", header = FALSE)
names(drugs) <- c("ID", "Age", "Gender", "Education", "Country", "Ethnicity", "Neuroticism", "Extraversion", "Openness", "Agreeableness", "Conscientiousness", "Impulsive", "SS", "Alcohol", "Amphet", "Amyl", "Benzos", "Caff", "Cannabis", "Choc", "Coke", "Crack", "Ecstasy", "Heroin", "Ketamine", "Legalh", "LSD", "Meth", "Mushrooms", "Nicotine", "Semer", "VSA")
drugs$Age <- as.factor(drugs$Age)
drugs$Gender  <- as.factor(drugs$Gender)
drugs$Education  <- as.factor(drugs$Education)
drugs$Country <- as.factor(drugs$Country)
drugs$Ethnicity <- as.factor(drugs$Ethnicity)
head(drugs)
# build a binary outcome variable
drugs$D_Meth <- "Meth"
drugs$D_Meth[drugs$Meth == "CL0"] <- "no_Meth"
drugs$D_Meth <- as.factor(drugs$D_Meth)
drugs$D_Meth <- relevel(drugs$D_Meth, "no_Meth")
table(drugs$Meth, drugs$D_Meth)
summary(drugs$D_Meth)
set.seed(9574)
inTrain <- createDataPartition(drugs$D_Meth,
p = .8,
list = FALSE,
times = 1)
drugs_train <- drugs[inTrain,]
drugs_test <- drugs[-inTrain,]
ctrl  <- trainControl(method = "cv",
number = 10,
summaryFunction = twoClassSummary,
classProbs = TRUE)
grid <- expand.grid(mtry = c(sqrt(ncol(drugs_train )),
log(ncol(drugs_train))),
splitrule = c("gini", "extratrees"),
min.node.size = 10)
grid
set.seed(9282)
rf <- train(D_Meth ~ Age + Gender + Education + Neuroticism + Extraversion +
Openness + Agreeableness + Conscientiousness + Impulsive + SS,
data = drugs_train,
method = "ranger",
trControl = ctrl,
tuneGrid = grid,
metric = "ROC",
importance = "impurity")
rf
# variable importance
plot(varImp(rf), top = 10)
# neuroticism and openness are the two most important variable.
# Partial plots
pdp1 <- partial(rf,pred.var = "Neuroticism",
type = "classification",
which.class = 1, prob = T)
# variable importance
plot(varImp(rf), top = 10)
# neuroticism and openness are the two most important variable.
# Partial plots
pdp1 <- partial(rf,pred.var = "Neuroticism",
type = "classification",
which.class = 1, prob = T)
# variable importance
plot(varImp(rf), top = 10)
# neuroticism and openness are the two most important variable.
# Partial plots
pdp1 <- partial(rf,pred.var = "Neuroticism",
type = "classification",
which.class = 1, prob = T)
# variable importance
plot(varImp(rf), top = 10)
# neuroticism and openness are the two most important variable.
# Partial plots
pdp1 <- partial(rf,pred.var = "Neuroticism",
type = "classification",
which.class = 1, prob = T)
# variable importance
plot(varImp(rf), top = 10)
# neuroticism and openness are the two most important variable.
# Partial plots
pdp1 <- partial(rf,pred.var = "Neuroticism",
type = "classification",
which.class = 1, prob = T)
# Partial plots
pdp1 <- partial(rf,pred.var = "Neuroticism",
type = "classification",
which.class = 1, prob = T)
# Partial plots
pdp1 <- partial(rf ,pred.var = "Neuroticism",
type = "classification",
which.class = 1, prob = T)
# Partial plots
pdp1 <- partial(rf,pred.var = "Neuroticism",
type = "classification",
which.class = 1, prob = T)
# Partial plots
pdp1 <- partial(rf,pred.var = "Neuroticism",
type = "classification",
which.class = 1, prob = T)
# Partial plots
pdp1 <- partial(rf,pred.var = "Neuroticism",
type = "classification",
which.class = 1, prob = T)
# Partial plots
pdp1 <- partial(rf,pred.var = "Neuroticism",
type = "classification",
which.class = 1, prob = T)
# Partial plots
pdp1 <- partial(rf,pred.var = "Neuroticism",
type = "classification",
which.class = 1, prob = T)
# Partial plots
pdp1 <- partial(rf,pred.var = "Neuroticism",
type = "classification",
which.class = 1, prob = T)
# Partial plots
pdp1 <- partial(rf,pred.var = "Neuroticism",
type = "classification",
which.class = 1, prob = T)
# Partial plots
pdp1 <- partial(rf,pred.var = "Neuroticism",
type = "classification",
which.class = 1, prob = T)
=======
=======
>>>>>>> 800ec3adac7cb9b72c7a95aff8947f0ec31743ee
=======
>>>>>>> a3617bf1d2a478fddcc5567148521e57438f9916
quote_places <-
tweets %>%
select(status_id, quoted_location, text) %>%
group_by(quoted_location) %>%
tally()
library(rtweet)
library(dplyr)
quote_places <-
tweets %>%
select(status_id, quoted_location, text) %>%
group_by(quoted_location) %>%
tally()
quote_places <-
tweets %>%
select(status_id, quoted_location, text) %>%
group_by(quoted_location) %>%
tally()
quote_places <-
tweets %>%
select(status_id, quoted_location, text) %>%
group_by(quoted_location) %>%
tally()
quote_places <-
tweets %>%
select(status_id, quoted_location, text) %>%
group_by(quoted_location) %>%
tally()
#checking number of observations
NROW(tweets)
#uploading packages
library(rtweet)
library(dplyr)
#uploading new data
tweets <- read_csv("tweets.csv")
#checking number of observations
NROW(tweets)
#checking place names
places <-
tweets %>%
select(status_id, place_name, text) %>%
group_by(place_name)%>%
tally()
#checking quotes locations
quote_places <-
tweets %>%
select(status_id, quoted_location, text) %>%
group_by(quoted_location) %>%
tally()
tweets <- read_csv("tweets.csv")
library(rtweet)
library(dplyr)
tweets <- read_csv("tweets.csv")
NROW(tweets)
library(tidyr)
tweets <- read_csv("tweets.csv")
#checking number of observations
NROW(tweets)
#checking place names
places <-
tweets %>%
select(status_id, place_name, text) %>%
group_by(place_name)%>%
tally()
#checking quotes locations
quote_places <-
tweets %>%
select(status_id, quoted_location, text) %>%
group_by(quoted_location) %>%
tally()
tweets <- read_csv("tweets.csv")
tweets <- read.csv("tweets.csv")
tweets <- read_csv("tweets.csv")
library(tidyr)
tweets <- read_csv("tweets.csv")
library(readr)
tweets <- read_csv("tweets.csv")
library(readr)
tweets <- read_csv("~/Data-cleaning/class-10/tweets.csv")
View(tweets)
quote_places <-
tweets %>%
select(status_id, quoted_location, text) %>%
group_by(quoted_location) %>%
tally()
quote_places
View(quote_places)
places <-
tweets %>%
select(status_id, place_name, text) %>%
group_by(place_name)%>%
tally()
places
View(places)
View(places)
users_data(tweets)
users <- users_data(tweets)
View(users)
View(users)
save_as_csv(users, users.csv)
save_as_csv(users)
save_as_csv(users, file_name = "twitter-users")
users %>%
select(screen_name, location, follwers_count) %>%
group_by(location)
users %>%
select(screen_name, location, followers_count) %>%
group_by(location)
users-location <-
users %>%
select(screen_name, location, followers_count) %>%
group_by(location)
users-location <-
users %>%
select(screen_name, location, followers_count) %>%
group_by(location)
users-location <-
users %>%
select(screen_name, location, followers_count) %>%
group_by(location)
users_location <-
users %>%
select(screen_name, location, followers_count) %>%
group_by(location)
View(users_location)
View(users_location)
users_location <-
users %>%
select(screen_name, location, followers_count) %>%
group_by(location) %>%
tally()
View(users_location)
View(users_location)
<<<<<<< HEAD
<<<<<<< HEAD
>>>>>>> b559b9e3032009a55493eeefc3a81b30b764f87d
=======
=======
>>>>>>> a3617bf1d2a478fddcc5567148521e57438f9916
library(rtweet)
library(dplyr)
library(tidyr)
library(readr)
library(rjson)
#setting working directory
setwd("~/Data-cleaning/final-paper/data")
#uploading tweet data
tweets <- read_csv("tweets.csv")
#uploading user data pulled from the tweet data
users <- read_csv("twitter-users.csv")
#importing voting reuslts
votes <- read_csv("~/Data-cleaning/final-paper/data/washington-2018-results.csv")
head(votes)
#uploading list of cities in washington to match with user information
cities <- read_csv("washington-cities.csv")
#we drop the NAs
users2 <-
users %>%
select(user_id, location, screen_name) %>%
drop_na(.)
#seperate the location column into city and state
users2 <- separate(users2, location, into = c("city","state"), sep= (","))
#get rid of all the white space
users2 <-
users2 %>%
select(user_id, screen_name, city) %>%
mutate(city = tolower(trimws(.$city)))
#then we need to clean the cities data
cities <-
cities %>%
mutate(city = tolower(trimws(.$city, "l")))
View(cities)
View(cities)
colnames(cities)[1] <- "city"
colnames(cities)[2] <- "county"
cities <-
cities %>%
mutate(city = tolower(trimws(.$city, "l")))
cities$city <- (gsub("\\s", "", cities$city))
full_location <- merge(users3, cities, by = "city")
full_location <- merge(users2, cities, by = "city")
View(full_location)
View(full_location)
full_location <-
full_location %>%
select(user_id, screen_name, city, county)
#annoyingly full_location has an extra x in the user id so need to remove
full_location$user_id <- gsub("x", "", full_location$user_id)
tweets$user_id <- gsub("x", "", tweets$user_id)
#merge user location with actual tweets
tweets_location <-
full_location %>% semi_join(tweets, by = "user_id")
View(full_location)
View(full_location)
View(tweets_location)
View(tweets_location)
votes <-
votes %>%
select(County, Race, Candidate, Votes, PercentageOfTotalVotes) %>%
filter(Race == "State Measures Initiative Measure No. 1639 Initiative Measure No. 1639 concerns firearms.")
View(tweets_location)
View(tweets_location)
View(tweets)
View(tweets)
colnames(tweets)
tweets_location <-
tweets %>%
select(user_id, screen_name, text, is_retweet, favorite_count, reply_count, retweet_count, hashtags, follwers_count)  %>%
tweets %>% semi_join(full_location, by = "user_id")
#merge user location with actual tweets
tweets_location <-
tweets %>%
select(user_id, screen_name, text, is_retweet, favorite_count, reply_count, retweet_count, hashtags, followers_count)  %>%
tweets %>% semi_join(full_location, by = "user_id")
tweets_location <-
tweets %>%
select(user_id, screen_name, text, is_retweet, favorite_count,
reply_count, retweet_count, hashtags, followers_count)  %>%
semi_join(full_location, by = "user_id")
View(full_location)
View(full_location)
View(tweets)
View(tweets)
View(tweets_location)
View(tweets_location)
View(votes)
View(votes)
View(tweets_location)
View(tweets_location)
tweets_location <-
tweets %>%
select(user_id, screen_name, text, is_retweet, favorite_count,
reply_count, retweet_count, hashtags, followers_count) %>%
merge(full_location, tweets by = "user_id")
tweets_location <-
tweets %>%
select(user_id, screen_name, text, is_retweet, favorite_count,
reply_count, retweet_count, hashtags, followers_count) %>%
merge(full_location, tweets, by = "user_id")
View(tweets)
View(tweets)
View(full_location)
View(full_location)
tweets_location <-
tweets %>%
select(user_id, screen_name, text, is_retweet, favorite_count,
reply_count, retweet_count, hashtags, followers_count) %>%
semi_join(full_location, tweets, by = "user_id")
View(tweets_location)
View(tweets_location)
tweets_location <-
tweets %>%
select(user_id, screen_name, text, is_retweet, favorite_count,
reply_count, retweet_count, hashtags, followers_count) %>%
semi_join(full_location, by = "user_id")
tweets_location <- merge(tweets_location, full_location, by = "user_id")
View(tweets_location)
View(tweets_location)
tweets_location <- semi_join(tweets_location, full_location, by = "user_id")
View(tweets_location)
View(tweets_location)
tweets_location <-
tweets %>%
select(user_id, screen_name, text, is_retweet, favorite_count,
reply_count, retweet_count, hashtags, followers_count)
online_users <- semi_join(tweets_location, full_location, by = "user_id")
View(online_users)
View(online_users)
online_users <- merge(tweets_location, full_location, by = "user_id")
View(online_users)
View(online_users)
library(ggmap)
citation("ggmap")
View(votes)
View(votes)
state = c(left = -124.84, bottom = 45.54,right = -116.92, top = 49.0)
get_stamenmap(state, zoom = 10, maptype = "toner-lite") %>% ggmap()
map <- get_stamenmap(state, zoom = 10, maptype = "toner-lite") %>% ggmap()
map <- get_stamenmap(state, zoom = 1, maptype = "toner-lite") %>% ggmap()
map
map <- get_stamenmap(state, zoom = 3, maptype = "toner-lite") %>% ggmap()
map
map <- get_stamenmap(state, zoom = 5, maptype = "toner-lite") %>% ggmap()
map
map <- get_stamenmap(state, zoom = 6, maptype = "toner-lite") %>% ggmap()
map
map <- get_stamenmap(state, zoom = 7, maptype = "toner-lite") %>% ggmap()
map
ggmap(map) +
geom_point(data= votes, aes(x = county, y = votes), size = 1)
ggmap() +
geom_point(data= votes, aes(x = county, y = votes), size = 1)
ggmap(map) +
geom_point(data= votes, aes(x = county, y = votes), size = 1)
qmap(map) +
geom_point(data= votes, aes(x = county, y = votes), size = 1)
qmplot(map) +
geom_point(data= votes, aes(x = county, y = votes), size = 1)
qmplot(state, data = votes, maptype = "toner-lite")
votes %>%
filter(Candidate == "Yes") %>%
qmplot(state, data = map)
votes %>%
filter(Candidate == "Yes") %>%
qmplot(state)
<<<<<<< HEAD
>>>>>>> 800ec3adac7cb9b72c7a95aff8947f0ec31743ee
=======
>>>>>>> a3617bf1d2a478fddcc5567148521e57438f9916
