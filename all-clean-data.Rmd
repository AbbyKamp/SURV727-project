---
title: "Combined-cleaned-data"
author: "Abigail Kamp and Rameesha Mehboob"
date: "November 19, 2019"
output: html_document
---

First, we load in all of our packages.

```{r}
library(rtweet)
library(dplyr)
library(tidyr)
library(readr)
library(rjson)
library(ggmap)
<<<<<<< HEAD
library(maps)
=======
<<<<<<< HEAD
library(tidyverse)
library(ggvis)
library(shiny)
=======
>>>>>>> 860c79174f509e5bc93b7f7d7bfdd48a28c2c80d

>>>>>>> a3617bf1d2a478fddcc5567148521e57438f9916
citation("ggmap")
```

Then we load in all of our data files. These files were downloaded from TWitter and the Washington Secretary of State webpage and saved as CSVs. 
```{r, cache=TRUE}

<<<<<<< HEAD
setwd("~/Desktop/Twitter")
=======
#setting working directory
setwd("~/Data-cleaning/final-paper/data")
>>>>>>> a3617bf1d2a478fddcc5567148521e57438f9916

#uploading tweet data
tweets <- read_csv("tweets.csv")

#uploading user data pulled from the tweet data
 users <- read_csv("twitter-users.csv")

#importing voting reuslts
<<<<<<< HEAD
votes <- read_csv("washington-2018-results.csv")
=======
votes <- read_csv("~/Data-cleaning/final-paper/data/washington-2018-results.csv")
>>>>>>> a3617bf1d2a478fddcc5567148521e57438f9916
head(votes)

#uploading list of cities in washington to match with user information
cities <- read_csv("washington-cities.csv")
```

## Twitter users vs. voters map

We need to clean the twitter users data and the city file to create a county location for all twitter users. 

```{r, results='hide'}
#we drop the NAs
users2 <-
  users %>%
   select(user_id, location, screen_name) %>%
   drop_na(.)

#seperate the location column into city and state
users2 <- separate(users2, location, into = c("city","state"), sep= (","))

#get rid of all the white space
users2 <-
users2 %>%
  select(user_id, screen_name, city) %>%
  mutate(city = tolower(trimws(.$city)))

#then we need to clean the cities data
colnames(cities)[1] <- "city"
colnames(cities)[2] <- "county"

cities <-
cities %>%
  mutate(city = tolower(trimws(.$city, "l")))

cities$city <- (gsub("\\s", "", cities$city))

#then we merge the dataframes
full_location <- merge(users2, cities, by = "city")

#reordering city variables
full_location <-
full_location %>%
  select(user_id, screen_name, city, county)

```

Then we combine the twitter user data with the tweets file, so that we have the location for all tweets were location was provided. (Twitter does not require users to disclose their location.)

```{r}
#annoyingly full_location has an extra x in the user id so need to remove
full_location$user_id <- gsub("x", "", full_location$user_id)
tweets$user_id <- gsub("x", "", tweets$user_id)

#merge user location with actual tweets
tweets_location <-
  tweets %>%
  select(user_id, screen_name, text, is_retweet, favorite_count,
<<<<<<< HEAD
         reply_count, retweet_count, hashtags, followers_count, created_at) 

#Method 1
data_final  <- tweets_location%>%
 inner_join(full_location, by = c("user_id" = "user_id"))

#Method 2
total <- merge(tweets_location,full_location,by=c("user_id","screen_name"))  
=======
         reply_count, retweet_count, hashtags, followers_count) 

#something weird is happening when I merge and I don't know why
online_users <- merge(tweets_location, full_location, by = "user_id")
>>>>>>> a3617bf1d2a478fddcc5567148521e57438f9916
 
```

We need to do some basic cleaning of the votes data so that we only have information on the 1631 referendum. We will also need to get the latitude and longitude for each county.

```{r}
votes <-
  votes %>%
  select(County, Race, Candidate, Votes, PercentageOfTotalVotes) %>%
  filter(Race == "State Measures Initiative Measure No. 1639 Initiative Measure No. 1639 concerns firearms.")%>%
  mutate(subregion= tolower(County))

```

<<<<<<< HEAD
# Mapping

Now I attempt to map the voting data. This first attempt uses get_stamenap to get a map of Washignton. It works but I don't think it has the counties. 
=======
<<<<<<< HEAD

```{r}
#Mapping the voting data
=======
Now I attempt to map the voting data. First I start by showing a map of Washington state
>>>>>>> 860c79174f509e5bc93b7f7d7bfdd48a28c2c80d

```{r}
>>>>>>> a3617bf1d2a478fddcc5567148521e57438f9916
#i use the ggmap package for this map
state = c(left = -124.84, bottom = 45.54,right = -116.92, top = 49.0)

map2 <- get_stamenmap(state, zoom = 7, maptype = "toner-lite") %>% ggmap()

#this makes a nice map with cities
map2+
  geom_path(aes(x= long, y= lat, group = group), data = vote_loc)

```

Then I download a Washington state map from the R "maps" package. I think this map looks a bit cleaner than the other map. 
```{r}
county<- map_data("county")

wash_counties <-
county %>%
  filter(region == "washington") 

#can we map these counties on top of our washington state map?
map2+
  geom_path(aes(x= long, y= lat, group = group), data = wash_counties)

w <- ggplot(data = wash_counties, mapping =aes(x= long, y= lat, group = group)) +
  geom_polygon(fill = "white", color = "black")

w

```

Now that we have our state map, we need to combine it with the voting data to visualize how people vote. 


```{r}
vote_loc <- left_join(wash_counties, votes, by = "subregion")

head(vote_loc)

```

```{r}

yes_votes <-
  vote_loc %>%
  filter(Candidate == "Yes") %>%
<<<<<<< HEAD
  mutate(PercentageOfTotalVotes = as.numeric(.$PercentageOfTotalVotes)) %>%
  mutate(Votes = as.numeric(.$Votes))


results <-  w +
  geom_polygon(data = yes_votes, aes(x= long, y= lat, fill = PercentageOfTotalVotes))


results
```



```{r}
```

```{r}

```

```{r}

=======
  qmplot(state)
<<<<<<< HEAD
```

```{r}
fav_count <- 
tweets_location%>%
  select(favorite_count,hashtags,reply_count)%>%
  drop_na(hashtags)%>%
  mutate(hashtags = tolower(hashtags)) %>%
  separate(., hashtags, into = c("hashtag1", "hashtag2", "hashtag3"),
           sep = " ")%>%
  group_by(hashtag1)%>%
  summarize_if(is.numeric, sum, na.rm=TRUE)
```

```{r}
ui <- fluidPage()
server <- function(input, output) {}
shinyApp(ui = ui, server = server)
```

```{r}
=======
>>>>>>> 860c79174f509e5bc93b7f7d7bfdd48a28c2c80d

```

```{r}


```

```{r}


```

```{r}


```

```{r}

<<<<<<< HEAD

```

```{r}


=======
>>>>>>> a3617bf1d2a478fddcc5567148521e57438f9916
>>>>>>> 860c79174f509e5bc93b7f7d7bfdd48a28c2c80d
```